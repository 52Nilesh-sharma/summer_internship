{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b60e34-2d98-4527-9b4a-43724cee923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def score_cleanliness(frame):\n",
    "    # Focus only on lower 40% of frame (ground assumption)\n",
    "    h = frame.shape[0]\n",
    "    roi = frame[int(h*0.6):, :]\n",
    "\n",
    "    # Convert to HSV for better color separation\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create mask for \"unusual\" colors (simulate litter: reds, blues, bright)\n",
    "    lower1 = np.array([0, 80, 60])\n",
    "    upper1 = np.array([10, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower1, upper1)  # red\n",
    "\n",
    "    lower2 = np.array([100, 100, 100])\n",
    "    upper2 = np.array([140, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv, lower2, upper2)  # blue/plastic\n",
    "\n",
    "    litter_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Find blobs of litter\n",
    "    contours, _ = cv2.findContours(litter_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    litter_area = sum(cv2.contourArea(c) for c in contours)\n",
    "    total_area = roi.shape[0] * roi.shape[1]\n",
    "    litter_ratio = litter_area / total_area\n",
    "\n",
    "    # Cleanliness scoring logic\n",
    "    score = max(0, 100 - int(litter_ratio * 250))  # heavier penalty\n",
    "    return score, contours, roi\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    zone = \"Zone A\"\n",
    "    last_cleaned = \"2024-06-01\"\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        score, litter_contours, roi = score_cleanliness(frame)\n",
    "\n",
    "        offset_y = int(frame.shape[0] * 0.6)\n",
    "        for cnt in litter_contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y + offset_y), (x + w, y + h + offset_y), (0, 0, 255), 2)\n",
    "\n",
    "        # Display Score\n",
    "        color = (0, 255, 0) if score > 75 else (0, 165, 255) if score > 50 else (0, 0, 255)\n",
    "        cv2.putText(frame, f\"Cleanliness Score: {score}%\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Zone: {zone} | Last Cleaned: {last_cleaned}\",\n",
    "                    (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow(\"ðŸ§¹ Cleanliness Estimator (Press Q to Quit)\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cc2be-1dd2-4945-ba21-01313a8b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# Initialize MediaPipe Hand Detector\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Define screen zones (OpenZone Concept)\n",
    "zones = {\n",
    "    \"top_left\": ((0, 0), (200, 200)),\n",
    "    \"top_right\": ((440, 0), (640, 200)),\n",
    "}\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmark in result.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(hand_landmark.landmark):\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "\n",
    "                # Tip of index finger\n",
    "                if id == 8:\n",
    "                    cv2.circle(frame, (cx, cy), 10, (255, 0, 255), -1)\n",
    "\n",
    "                    # Zone Detection\n",
    "                    for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "                        if x1 <= cx <= x2 and y1 <= cy <= y2:\n",
    "                            cv2.putText(frame, f\"TAP: {zone_name}\", (x1, y1 - 10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "                            # Simulate mouse click if needed\n",
    "                            if zone_name == \"top_right\":\n",
    "                                pyautogui.click()\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            mp_draw.draw_landmarks(frame, hand_landmark, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Draw Zones\n",
    "    for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "        cv2.putText(frame, zone_name, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Virtual Touchscreen\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a0dac0-3a7a-4b27-8176-85a08635c581",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcvzone\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mHandTrackingModule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyautogui\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Webcam capture\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\site-packages\\cvzone\\HandTrackingModule.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmp\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mHandDetector\u001b[39;00m:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    Finds Hands using the mediapipe library. Exports the landmarks\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    in pixel format. Adds extra functionalities like finding how\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    many fingers are up or the distance between two fingers. Also\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    provides bounding box info of the hand found.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import pyautogui\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)  # Width\n",
    "cap.set(4, 480)  # Height\n",
    "\n",
    "# Initialize detector\n",
    "detector = HandDetector(maxHands=1, detectionCon=0.8)\n",
    "\n",
    "# Define screen zones (OpenZone-style virtual buttons)\n",
    "zones = {\n",
    "    \"top_left\": ((0, 0), (200, 200)),\n",
    "    \"top_right\": ((440, 0), (640, 200)),\n",
    "}\n",
    "\n",
    "clicked_zone = None\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        lmList = hands[0][\"lmList\"]  # 21 Landmark points\n",
    "        index_finger_tip = lmList[8]  # Index finger tip\n",
    "        x, y = index_finger_tip[0], index_finger_tip[1]\n",
    "\n",
    "        cv2.circle(img, (x, y), 10, (255, 0, 255), -1)\n",
    "\n",
    "        for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                if clicked_zone != zone_name:\n",
    "                    print(f\"Clicked: {zone_name}\")\n",
    "                    pyautogui.click()\n",
    "                    clicked_zone = zone_name\n",
    "                cv2.putText(img, f\"TAPPED: {zone_name}\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                break\n",
    "        else:\n",
    "            clicked_zone = None\n",
    "\n",
    "    # Draw zones\n",
    "    for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "        cv2.putText(img, zone_name, (x1, y2 + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Virtual Touchscreen\", img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39557876-4dd8-499e-95fc-999cfe6835db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "\n",
    "# Setup webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Define OpenZone-style virtual buttons\n",
    "zones = {\n",
    "    \"Top Left\": ((0, 0), (200, 200)),\n",
    "    \"Top Right\": ((440, 0), (640, 200)),\n",
    "}\n",
    "\n",
    "clicked_zone = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert to HSV for better color detection\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define green color range (you can adjust this if needed)\n",
    "    lower_green = np.array([35, 60, 60])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "\n",
    "    # Create mask\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Process largest green object (your finger tip with green tape)\n",
    "    if contours:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(max_contour) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(max_contour)\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "\n",
    "            # Draw center point\n",
    "            cv2.circle(frame, (cx, cy), 10, (255, 0, 255), -1)\n",
    "\n",
    "            # Check zones\n",
    "            for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "                if x1 <= cx <= x2 and y1 <= cy <= y2:\n",
    "                    if clicked_zone != zone_name:\n",
    "                        print(f\"Touch Detected in Zone: {zone_name}\")\n",
    "                        pyautogui.click()\n",
    "                        clicked_zone = zone_name\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                    cv2.putText(frame, f\"CLICK: {zone_name}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    break\n",
    "            else:\n",
    "                clicked_zone = None\n",
    "\n",
    "    # Draw zones\n",
    "    for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "        cv2.putText(frame, zone_name, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Touchscreen via Webcam\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7885fdd-8c5c-44b5-aef3-df0093ae1fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n",
      "Clicked on: top_left\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "\n",
    "# Define Zones like virtual buttons\n",
    "zones = {\n",
    "    \"top_left\": ((0, 0), (200, 200)),\n",
    "    \"top_right\": ((440, 0), (640, 200)),\n",
    "}\n",
    "\n",
    "clicked_zone = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    roi = frame.copy()\n",
    "\n",
    "    # Convert to HSV and threshold skin color\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Blur and find contours\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 100)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours and len(contours) > 0:\n",
    "        # Find largest contour (most likely hand)\n",
    "        contour = max(contours, key=lambda x: cv2.contourArea(x))\n",
    "        if cv2.contourArea(contour) > 1000:\n",
    "            # Draw contour\n",
    "            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "            # Find convex hull\n",
    "            hull = cv2.convexHull(contour)\n",
    "            cv2.drawContours(frame, [hull], -1, (255, 0, 0), 2)\n",
    "\n",
    "            # Find fingertip (highest y)\n",
    "            top = tuple(contour[contour[:, :, 1].argmin()][0])\n",
    "            cv2.circle(frame, top, 10, (0, 0, 255), -1)\n",
    "\n",
    "            x, y = top\n",
    "\n",
    "            # Check if finger is in a zone\n",
    "            for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "                if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                    if clicked_zone != zone_name:\n",
    "                        print(f\"Clicked on: {zone_name}\")\n",
    "                        pyautogui.click()\n",
    "                        clicked_zone = zone_name\n",
    "                    cv2.putText(frame, f\"TAP: {zone_name}\", (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    break\n",
    "            else:\n",
    "                clicked_zone = None\n",
    "\n",
    "    # Draw static zones\n",
    "    for zone_name, ((x1, y1), (x2, y2)) in zones.items():\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 1)\n",
    "        cv2.putText(frame, zone_name, (x1, y2 + 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Virtual Touch via Camera\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205d952-6c57-40e4-a99f-e7a3e460edd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
